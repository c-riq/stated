# Artificial Intelligence Safety

There is a risk of Artificial General Intelligence being created which then cannot be controled by humans due to it's vastly higher intelligence.<br />
Following the process of evolution, variants of this AGI will then eventually displace humans just as humans are currently displacing most other species on earth solely based on their intellectual capabilities.<br />
Developling such powerful AGI's would therefore be a collective suicide of humanity.<br />
Many researches working on AI have expressed this concern, however without efficient international coordination, we may not be able to sufficiently control further developments in time.<br />
<br />

## Accelerate the creation of rules

Recommendations to legislators will have a higher chance of success, if they are publicly endorsed by many organizations.
These endorsements should to be independently verifiable to mitigate fake endorsements.
An example recommendation could be:
“Ban large AI training runs using more than 10^23 FLOP.” - endorsed by 100 organizations

## International enforcement of rules
An example for this could be:
“We will boycott any business with companies that do not comply with guideline XYZ for safe AI development”
endorsed by 5000 companies

